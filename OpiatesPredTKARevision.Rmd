---
title: "Preoperative Opiate Use As A Predictor Of Total-Knee Arthroplasty Revision"
author: "Jordan Starr"
date: "September 23, 2015"
output: html_document
---

##Load Data & Packages
```{r cache=TRUE}
knitr::opts_chunk$set(cache=T)
library("dplyr")
library("caret")
library("ROCR")
library("scales")
library("randomForest")
set.seed(12)
alldata <- read.csv("WorkDf5.csv", sep=";")
```

##Clean Data
```{r cache=TRUE}
names(alldata)
```
Remove unnecessary columns
```{r cache=TRUE}
data <- alldata[,c(5:8,19,26:32,39,47)]
str(data)
```
Set correct variable types
```{r cache=TRUE}
data$Diabetes <- as.factor(data$Diabetes)
data$CKD <- as.factor(data$CKD)
data$HTN <- as.factor(data$HTN)
data$CHF <- as.factor(data$CHF)
data$OSA <- as.factor(data$OSA)
data$PTSD <- as.factor(data$PTSD)
data$Tobbaco <- as.factor(data$Tobbaco)
data$RevLogical <- as.factor(data$RevLogical)
```
Check distribution of height variable, remove spurious values.
```{r cache=TRUE}
ggplot(data=data, aes(data$ht)) + geom_histogram() + coord_cartesian(ylim=c(0, 20)) + scale_x_continuous(breaks=seq(0, 100, 4))
data$ht <- ifelse(data$ht < 48 | data$ht > 86, NA, data$ht)
```
Check distribution of weight variable, remove spuriuos values.
```{r cache=TRUE}
ggplot(data=data, aes(data$wt)) + geom_histogram() + coord_cartesian(ylim=c(0, 30))
ggplot(data=data, aes(data$wt)) + geom_histogram() + coord_cartesian(ylim=c(0, 30),xlim=c(0,100)) + scale_x_continuous(breaks=seq(0, 100, 4))
data$wt <- ifelse(data$wt < 80 | data$wt > 600, NA, data$wt)
```
Create BMI variable:
```{r cache=TRUE}
data <- mutate(data, BMI = (wt/2.2)/(ht*2.54/100)^2)
```
Create morphine equivalent dose per month variable:
```{r cache=TRUE}
data$MEDperMonth <- ifelse(data$TimeBefore==0, 0, data$med_load/data$TimeBefore)
```
Check MEDperMonth distribution and remove significant outliers:
```{r cache=TRUE}
ggplot(data=data, aes(data$MEDperMonth)) + geom_histogram() + coord_cartesian(ylim=c(0,5)) + scale_x_continuous(breaks=seq(50000,150000,10000))+theme(axis.text.x = element_text(angle = 45, hjust = 1))
data$MEDperMonth <- ifelse(data$MEDperMonth > 80000, NA, data$MEDperMonth)
```
Convert dependent variable to usable factors for future probability functions:
```{r cache=TRUE}
data$RevLogical <- factor(data$RevLogical, levels = c(0,1),labels = c("no", "yes"))
```

Remove ht and wt columns (already in BMI), remove med_load and TimeBefore (accounted for in MEDperMonth), and then trim dataset of NAs
```{r cache=TRUE}
cleandata <- data[,c(-3:-5,-14)]
completeData <- na.omit(cleandata)
```

##Data Analysis

Multivariate Logistic Regression Controlling for All Variables on Whole Dataset
```{r cache=TRUE}
glmfitall <- glm(RevLogical ~ ., data = completeData, family = "binomial")
summary(glmfitall) #coefficients and p-values
```

These are the odds ratios and associated 95% confidence intervals.
```{r cache=TRUE}
a <- exp(coef(glmfitall)) # Odds ratios
a
b <- exp(confint(glmfitall)) # Confidence intervals
b
```

Forest Plot (not used so unfinished):
```{r}
tmp<-data.frame(cbind(exp(coef(glmfitall)), exp(confint(glmfitall))))
odds<-tmp[-1,]
names(odds)<-c('OR', 'Lower', 'Upper')
odds$vars<-row.names(odds)
     
g <- ggplot(odds, aes(y= OR, x = reorder(vars, OR))) + geom_point() + geom_errorbar(aes(ymin=Lower, ymax=Upper), width=.2) + geom_hline(yintercept = 1, linetype=2) + coord_flip() + labs(title = "Title", x = "Variables", y = "OR") + theme_bw() + scale_y_continuous(breaks=c(0,.5,1,1.5,2,2.5,3))
g
```

Calculation for relative risk change by opiate use (assuming OR ~ RR given low frequency of TKA revision):
```{r cache=TRUE}
# Baseline absolute risk of revision in opiate naive patients:
u <- subset(completeData, MEDperMonth == 0)
percent(length(u$RevLogical[u$RevLogical == "yes"])/length(u$RevLogical))

# Calculate monthly morphine equivalents for a typical patient on oxycodone 5 mg q6h (oxycodone to morphine ratio of 2:3):
5*1.5*4*365/12

# Calculate relative risk increase (2.506e-05 = MEDperMonth coefficient):
percent((2.506e-05*912.5)/ (length(u$RevLogical[u$RevLogical == "yes"])/length(u$RevLogical)))
```

Relative risk by MED per day line graph
```{r}
x <- 1:100
#100 converts to percent, 2.50e-05 is coefficient of MEDperMonth, 365/12 converts daily dose to monthly dose to match coefficient, and 0.039 is absolute risk of opiate naive patients
y <- 100*2.506e-05*(365/12)*x/0.03920426
g <- qplot(x, y, main="Increase in Relative Risk of Revision \n by Daily Morphine Equivalent Dose", xlab="Daily Morphine Equivalent Dose", ylab="Percent Relative Risk Increase", geom="line")
g
```

## Machine Learning Analysis

Training, testing, and validation datasets:
```{r}
inTrain <- createDataPartition(y=completeData$RevLogical, p = .6, list=FALSE)
training <- completeData[inTrain, ]
testingboth <- completeData[-inTrain, ]
inTrain2 <- createDataPartition(y=testingboth$RevLogical, p = .5, list =F)
testing <- testingboth[inTrain2,]
validation <- testingboth[-inTrain2,]
```

GLM with 10-fold cross validation
```{r}
ctrl <- trainControl(method="cv", number=10, classProbs = TRUE)
glmfit <- train(RevLogical ~ ., data = training, method="glm", trControl = ctrl)
pred1 <- predict(glmfit, testing, type="prob")
x <- prediction(pred1[,2],testing$RevLogical)
y <- performance(x, measure = "tpr", x.measure = "fpr")
plot(y)
abline(a=0, b= 1)
z <- performance(x, measure = "auc")
p <- unlist(z@y.values)
n <- nrow(training)
s = sqrt(p*(1-p)/n)
CI <- c(p-1.96*s, p+1.96*s)
p #AUC
CI #AUC 95% CI
```

Step-wise glm
```{r}
#glmfit varImp order: Age, CKD, Diabetes, MEDperMonth, Tobbaco, BMI, PTSD, gender, HTN, CHF, OSA
glmfit1 <- glm(RevLogical ~ Age, data = training, family = "binomial")
glmfit2 <- glm(RevLogical ~ Age + CKD, data = training, family = "binomial")
glmfit3 <- glm(RevLogical ~ Age + CKD + Diabetes, data = training, family = "binomial")
glmfit4 <- glm(RevLogical ~ Age + CKD + Diabetes + MEDperMonth, data = training, family = "binomial")
anova(glmfit1, glmfit2, glmfit3, glmfit4, test = "Chisq")
```

Model with top 3 variables best:
```{r}
ctrl <- trainControl(method="cv", number=10, classProbs = TRUE)
glmfit3 <- train(RevLogical ~ Age + CKD + Diabetes, data = training, method="glm", trControl = ctrl)
pred2 <- predict(glmfit3, testing, type="prob")
x <- prediction(pred2[,2],testing$RevLogical)
y <- performance(x, measure = "tpr", x.measure = "fpr")
plot(y)
abline(a=0, b= 1)
z <- performance(x, measure = "auc")
p <- unlist(z@y.values)
n <- nrow(training)
s = sqrt(p*(1-p)/n)
CI <- c(p-1.96*s, p+1.96*s)
p #AUC
CI #AUC 95% CI
```

Rpart
```{r}
rpartfit <- train(RevLogical ~ ., data = training, method="rpart")
pred3 <- predict(rpartfit, testing, type="prob")
x <- prediction(pred3[,2],testing$RevLogical)
y <- performance(x, measure = "tpr", x.measure = "fpr")
plot(y)
abline(a=0, b= 1)
z <- performance(x, measure = "auc")
p <- unlist(z@y.values)
n <- nrow(training)
s = sqrt(p*(1-p)/n)
CI <- c(p-1.96*s, p+1.96*s)
p #AUC
CI #AUC 95% CI
```

Boosting
```{r}
gbmfit <- train(RevLogical ~ ., data = training, method="gbm", verbose = F)
pred4 <- predict(gbmfit, testing, type="prob")
x <- prediction(pred4[,2],testing$RevLogical)
y <- performance(x, measure = "tpr", x.measure = "fpr")
plot(y)
abline(a=0, b= 1)
z <- performance(x, measure = "auc")
p <- unlist(z@y.values)
n <- nrow(training)
s = sqrt(p*(1-p)/n)
CI <- c(p-1.96*s, p+1.96*s)
p #AUC
CI #AUC 95% CI
```

Glmnet with 10-fold cross validation
```{r}
ctrl <- trainControl(method="cv", number=10, classProbs = TRUE)
glmnetfit <- train(RevLogical ~ ., data = training, method="glmnet", trControl = ctrl)
coef(glmnetfit$finalModel, s = glmnetfit$bestTune[,2]) #gives used coefficients
pred5 <- predict(glmnetfit, testing, type = "prob")
x <- prediction(pred5[,2],testing$RevLogical)
y <- performance(x, measure = "tpr", x.measure = "fpr")
plot(y)
abline(a=0, b= 1)
z <- performance(x, measure = "auc")
p <- unlist(z@y.values)
n <- nrow(training)
s = sqrt(p*(1-p)/n)
CI <- c(p-1.96*s, p+1.96*s)
p #AUC
CI #AUC 95% CI
```

Naive Bayes
```{r}
nbfit <- train(RevLogical ~ ., data = training, method="nb")
pred6 <- predict(nbfit, testing, type="prob")
x <- prediction(pred6[,2],testing$RevLogical)
y <- performance(x, measure = "tpr", x.measure = "fpr")
plot(y)
abline(a=0, b= 1)
z <- performance(x, measure = "auc")
p <- unlist(z@y.values)
n <- nrow(training)
s = sqrt(p*(1-p)/n)
CI <- c(p-1.96*s, p+1.96*s)
p #AUC
CI #AUC 95% CI
```

Random Forest
```{r}
rffit <- randomForest(RevLogical ~ ., data=training, importance=TRUE)
pred7 <- predict(rffit, testing, type="prob")
x <- prediction(pred7[,2],testing$RevLogical)
y <- performance(x, measure = "tpr", x.measure = "fpr")
plot(y)
abline(a=0, b= 1)
z <- performance(x, measure = "auc")
p <- unlist(z@y.values)
n <- nrow(training)
s = sqrt(p*(1-p)/n)
CI <- c(p-1.96*s, p+1.96*s)
p #AUC
CI #AUC 95% CI
```

Combined Model
```{r}
predDF <- data.frame(pred1 = pred1[,2], pred2 = pred2[,2], pred3 = pred3[,2], pred4 = pred4[,2], pred5 = pred5[,2], pred6 = pred6[,2], pred7 = pred7[,2],RevLogical = testing$RevLogical)
combModFit <- train(RevLogical ~ ., data = predDF, method = "gam")
pred1V <- predict(glmfit, validation, type = "prob")
pred2V <- predict(glmfit3, validation, type = "prob")
pred3V <- predict(rpartfit, validation, type = "prob")
pred4V <- predict(gbmfit, validation, type = "prob")
pred5V <- predict(glmnetfit, validation, type = "prob")
pred6V <- predict(nbfit, validation, type = "prob")
pred7V <- predict(rffit, validation, type = "prob")
predVDF <- data.frame(pred1 = pred1V[,2], pred2 = pred2V[,2], pred3 = pred3V[,2], pred4 = pred4V[,2], pred5 = pred5V[,2], pred6 = pred6V[,2], pred7 = pred7V[,2])
combPredV <- predict(combModFit, predVDF, type = "prob")
x <- prediction(combPredV[,1],validation$RevLogical)
y <- performance(x, measure = "tpr", x.measure = "fpr")
plot(y)
abline(a=0, b= 1)
z <- performance(x, measure = "auc")
p <- unlist(z@y.values)
n <- nrow(training)
s = sqrt(p*(1-p)/n)
CI <- c(p-1.96*s, p+1.96*s)
p #AUC
CI #AUC 95% CI
```

Notes for paper:
glmfit (11) AUROC = 0.616, 0.609-0.623
glmfit3 (3) AUROC = 0.617, 0.609-0.624
rpartfit (11) AUROC = 0.5, 0.493-0.507
gbmfit (11) AUROC = 0.622, 0.615-0.629
glmnetfit (10) AUROC = 0.615, 0.608-0.622
nbfit (11) AUROC = 0.591, 0.584-0.599
rffit (11) AUROC = 0.572, 0.564-0.579
combModFit (11) AUROC = 0.631, 0.624-0.638

## Calculate RMSE of probability plot for all 8 models:

glmfit
```{r}
testing <- mutate(testing, risk = predict(glmfit, testing, type = "prob")[,2])
testing$decile <- cut(testing$risk, breaks = 10, labels = F)
testinggrp <- group_by(testing, decile)
z <- summarise(testinggrp, pred_rev = round(sum(risk)), obs_rev = sum(ifelse(RevLogical == "yes",1,0)), min_risk = round(min(risk),3), max_risk = round(max(risk),3))
z
sqrt(mean((z[,3]-z[,2])^2)) 
p <- plot(unlist(z[,2]),unlist(z[,3]))
p
abline(0,1)
```

glmfit3
```{r}
testing <- testing[,c(-13,-14)] #to reset testing data 
testing <- mutate(testing, risk = predict(glmfit3, testing, type = "prob")[,2])
testing$decile <- cut(testing$risk, breaks = 10, labels = F)
testinggrp <- group_by(testing, decile)
z <- summarise(testinggrp, pred_rev = round(sum(risk)), obs_rev = sum(ifelse(RevLogical == "yes",1,0)), min_risk = round(min(risk),3), max_risk = round(max(risk),3))
z
sqrt(mean((z[,3]-z[,2])^2)) 
p <- plot(unlist(z[,2]),unlist(z[,3]))
p
abline(0,1)
```

rpartfit
```{r}
testing <- testing[,c(-13,-14)] #to reset testing data 
testing <- mutate(testing, risk = predict(rpartfit, testing, type = "prob")[,2])
testing$decile <- cut(testing$risk, breaks = 10, labels = F)
testinggrp <- group_by(testing, decile)
z <- summarise(testinggrp, pred_rev = round(sum(risk)), obs_rev = sum(ifelse(RevLogical == "yes",1,0)), min_risk = round(min(risk),3), max_risk = round(max(risk),3))
z
sqrt(mean((z[,3]-z[,2])^2)) 
p <- plot(unlist(z[,2]),unlist(z[,3]))
p
abline(0,1)
```

gbmfit
```{r}
testing <- testing[,c(-13,-14)] #to reset testing data 
testing <- mutate(testing, risk = predict(gbmfit, testing, type = "prob")[,2])
testing$decile <- cut(testing$risk, breaks = 10, labels = F)
testinggrp <- group_by(testing, decile)
z <- summarise(testinggrp, pred_rev = round(sum(risk)), obs_rev = sum(ifelse(RevLogical == "yes",1,0)), min_risk = round(min(risk),3), max_risk = round(max(risk),3))
z
sqrt(mean((z[,3]-z[,2])^2)) 
p <- plot(unlist(z[,2]),unlist(z[,3]))
p
abline(0,1)
```

glmnetfit
```{r}
testing <- testing[,c(-13,-14)] #to reset testing data 
testing <- mutate(testing, risk = predict(glmnetfit, testing, type = "prob")[,2])
testing$decile <- cut(testing$risk, breaks = 10, labels = F)
testinggrp <- group_by(testing, decile)
z <- summarise(testinggrp, pred_rev = round(sum(risk)), obs_rev = sum(ifelse(RevLogical == "yes",1,0)), min_risk = round(min(risk),3), max_risk = round(max(risk),3))
z
sqrt(mean((z[,3]-z[,2])^2)) 
p <- plot(unlist(z[,2]),unlist(z[,3]))
p
abline(0,1)
```

nbfit
```{r}
testing <- testing[,c(-13,-14)] #to reset testing data 
testing <- mutate(testing, risk = predict(nbfit, testing, type = "prob")[,2])
testing$decile <- cut(testing$risk, breaks = 10, labels = F)
testinggrp <- group_by(testing, decile)
z <- summarise(testinggrp, pred_rev = round(sum(risk)), obs_rev = sum(ifelse(RevLogical == "yes",1,0)), min_risk = round(min(risk),3), max_risk = round(max(risk),3))
z
sqrt(mean((z[,3]-z[,2])^2)) 
p <- plot(unlist(z[,2]),unlist(z[,3]))
p
abline(0,1)
```

rffit
```{r}
testing <- testing[,c(-13,-14)] #to reset testing data 
testing <- mutate(testing, risk = predict(rffit, testing, type = "prob")[,2])
testing$decile <- cut(testing$risk, breaks = 10, labels = F)
testinggrp <- group_by(testing, decile)
z <- summarise(testinggrp, pred_rev = round(sum(risk)), obs_rev = sum(ifelse(RevLogical == "yes",1,0)), min_risk = round(min(risk),3), max_risk = round(max(risk),3))
z
sqrt(mean((z[,3]-z[,2])^2)) 
p <- plot(unlist(z[,2]),unlist(z[,3]))
p
abline(0,1)
```

combModFit
```{r}
predVDF$RevLogical <- validation$RevLogical
predVDF <- mutate(predVDF, risk = predict(combModFit, predVDF, type = "prob")[,1])
predVDF$decile <- cut(predVDF$risk, breaks = 10, labels = F)
predVDFgrp <- group_by(predVDF, decile)
z <- summarise(predVDFgrp, pred_rev = round(sum(risk)), obs_rev = sum(ifelse(RevLogical == "yes",1,0)), min_risk = round(min(risk),3), max_risk = round(max(risk),3))
z
sqrt(mean((z[,3]-z[,2])^2)) 
p <- plot(unlist(z[,2]),unlist(z[,3]))
p
abline(0,1)
```

Notes for paper:
glmfit (11) RMSE = 3.66
glmfit3 (3) RMSE = 2.77
rpartfit (11) RMSE = 0 (1 decile)
gbmfit (11) RMSE = 3.10
glmnetfit (10) RMSE = 4.25
nbfit (11) RMSE = 110.39
rffit (11) RMSE = 48.97
combModFit (11) RMSE = 7.20

## Validation with glmfit3:
```{r}
#AUROC
finalpred <- predict(glmfit3, validation, type="prob")
x <- prediction(finalpred[,2],validation$RevLogical)
y <- performance(x, measure = "tpr", x.measure = "fpr")
plot(y)
abline(a=0, b= 1)
z <- performance(x, measure = "auc")
p <- unlist(z@y.values)
n <- nrow(training)
s = sqrt(p*(1-p)/n)
CI <- c(p-1.96*s, p+1.96*s)
p #AUC
CI #AUC 95% CI

#RMSE
validation <- mutate(validation, risk = predict(glmfit3, validation, type = "prob")[,2])
validation$decile <- cut(validation$risk, breaks = 10, labels = F)
validationgrp <- group_by(validation, decile)
z <- summarise(validationgrp, pred_rev = round(sum(risk)), obs_rev = sum(ifelse(RevLogical == "yes",1,0)), min_risk = round(min(risk),3), max_risk = round(max(risk),3))
z
sqrt(mean((z[,3]-z[,2])^2)) 
p <- plot(unlist(z[,2]),unlist(z[,3]))
p
abline(0,1)
```

Notes for paper:
glmfit3 validation AUROC: 0.623, 0.616-0.630
glmfit3 validation RMSE: 1.667

## Graphs

Reliability curve for glmfit3
```{r}
g <- ggplot(z, aes(unlist(z[,2]),unlist(z[,3]))) + geom_point() + labs(title = "Reliability Plot of TKA Revision Prediction Model", x = "Predicted Revisions", y = "Observed Revisions") + geom_abline(intercept = 0, slope = 1) + coord_cartesian(xlim = c(0,115), ylim = c(0,115)) + annotate("text", x = 30, y = 75, label = "RMSE = 1.67")
ppi <- 300
png("Reliability.png", width = 6*ppi, height = 6*ppi, res = ppi)
g
dev.off()
pdf("Reliability.pdf")
g
dev.off()
```

All ROCs combined:
```{r}
library("RColorBrewer")
allpreds <- list(pred1[,2],pred2[,2],pred3[,2],pred4[,2],pred5[,2],pred6[,2],pred7[,2],combPredV[,1])
alllabs <- list(testing$RevLogical,testing$RevLogical,testing$RevLogical,testing$RevLogical,testing$RevLogical,testing$RevLogical,testing$RevLogical,validation$RevLogical)
x <- prediction(allpreds,alllabs)
y <- performance(x, measure = "tpr", x.measure = "fpr")
c <- as.list(brewer.pal(8,"Set1"))
ppi <- 300
png("ROC.png", width = 6*ppi, height = 6*ppi, res = ppi)
p <- plot(y, main="ROC of all TKA Revision Models", xlab="False Positive Rate", ylab="True Positive Rate", col=c, lwd=2)
abline(a=0, b= 1)
legend("topleft", legend = c("Generalized Linear","Stepwise Generalized Linear (3 Variables)", "Recursive Partitioning and Regression Trees", "Gradient Boosting","Lasso","Naive Bayes", "Random Forest", "7-Model Composite"),lty=1, lwd=3, col=c(c[[1]], c[[2]],c[[3]],c[[4]],c[[5]],c[[6]],c[[7]],c[[8]]), cex=.7, bty="n", y.intersp=.75, title="Models", title.adj = .2, seg.len=1.5)
dev.off()

pdf("ROC.pdf")
p <- plot(y, main="ROC of all TKA Revision Models", xlab="False Positive Rate", ylab="True Positive Rate", col=c, lwd=2)
abline(a=0, b= 1)
legend("topleft", legend = c("Generalized Linear (3 Variables)", "Generalized Linear","Gradient Boosting","Lasso","Naive Bayes", "Random Forest", "Models 2-6 Composite", "Recursive Partitioning and Regression Trees"),lty=1, lwd=3, col=c(c[[6]],c[[1]],c[[2]],c[[3]],c[[4]],c[[5]],c[[8]],c[[7]]), cex=.8, bty="n", y.intersp=.75, title="Models", title.adj = .2, seg.len=1.5)
dev.off()
```